{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c40ac77",
   "metadata": {},
   "source": [
    "# BUSINESS ANALYTICS\n",
    "## STUDY CASE: Lending Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d393e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "import collections\n",
    "import os\n",
    "import warnings\n",
    "from sys import platform\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, brier_score_loss, mean_squared_error\n",
    "from sklearn.metrics import r2_score, auc, precision_recall_curve, f1_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Sklearn classifiers\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LassoLars\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "# Other packages\n",
    "from scipy.stats import kendalltau\n",
    "from six import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Load debugger, if required\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37df39",
   "metadata": {},
   "source": [
    "## WK1/Phase1 - Ingestion and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fea01a",
   "metadata": {},
   "source": [
    "### Step 1 - Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce907e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_integer(x):\n",
    "    '''\n",
    "    This function returns True if x is an integer, and False otherwise\n",
    "    '''\n",
    "    try:\n",
    "        return (int(x) == float(x))\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbce10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using Windows\n",
    "dir_data = \"C:\\\\Users\\\\ly266e\\\\Documents\\\\Training\\\\CMU\\\\Master\\\\Fall 2023 Mini 7\\\\Business_Analytics\\\\HW\\\\HW6\\\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca0ec0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, final\n",
    "def ingest_files(directory: str) -> Dict:\n",
    "    '''\n",
    "    This function will ingest every file in the specified directory\n",
    "    into a pandas dataframe. It will return a dictionary containing\n",
    "    these dataframes, keyed by the file name.\n",
    "    \n",
    "    We assume the directory contains files directly downloaded from\n",
    "    Lending Club, and *only* those files. Thus, we assume the files are zipped\n",
    "    (pd.read_csv can read zipped files) and we assume the first line\n",
    "    in each file needs to be skipped. \n",
    "    \n",
    "    Note that this function will read and ingest more than one file and is\n",
    "    convenient if you want to ingest data for more than one year at a time.\n",
    "    \n",
    "    Note that each file will be read *without* formatting\n",
    "    '''\n",
    "    \n",
    "    # If the directory has no trailing slash, add one\n",
    "    if directory[-1] != \"/\":\n",
    "        directory = directory + \"/\"\n",
    "    \n",
    "    all_files = os.listdir(directory)\n",
    "    output = {}\n",
    "    \n",
    "    print(\"Directory \" + directory + \" has \" + str(len(all_files)) + \" files:\")\n",
    "    for i in all_files:\n",
    "        print(\"    Reading file \" + i)\n",
    "        output[i] = pd.read_csv(directory + i, dtype = str, skiprows = 1)\n",
    "        \n",
    "        # Some of the files have \"summary\" lines that, for example\n",
    "        # read \"Total number of loans number in Policy 1: .....\"\n",
    "        # To remove those lines, find any lines with non-integer IDs\n",
    "        # and remove them\n",
    "        invalid_rows = (output[i].id.apply( lambda x : is_integer(x) == False ))\n",
    "        if invalid_rows.sum() > 0:\n",
    "            print(\"        Found \" + str(invalid_rows.sum()) + \" invalid rows which were removed\")\n",
    "            output[i] = output[i][invalid_rows == False]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a02a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\ly266e\\Documents\\Training\\CMU\\Master\\Fall 2023 Mini 7\\Business_Analytics\\HW\\HW6\\Data/ has 2 files:\n",
      "    Reading file LoanStats3c.csv\n",
      "        Found 4 invalid rows which were removed\n",
      "    Reading file LoanStats3d.csv\n",
      "        Found 5 invalid rows which were removed\n"
     ]
    }
   ],
   "source": [
    "# Ingest the set of files we downloaded \n",
    "files_data = ingest_files(dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23ebd498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LoanStats3c.csv', 'LoanStats3d.csv'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a9faea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_now = pd.concat(files_data.values()).reset_index(drop = True)\n",
    "columns = list(data_now.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c38f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns is: 144\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of columns is: {len(columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1a1398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 656724 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting with \" + str(len(data_now)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c61e2",
   "metadata": {},
   "source": [
    "### Step 2 - Choose Columns and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e14413d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns we'll be keeping from the dataset\n",
    "cols_to_pick = ['id','loan_amnt','funded_amnt','term','int_rate'\n",
    "                ,'grade','emp_length', 'home_ownership',\n",
    "                'annual_inc','verification_status','issue_d',\n",
    "                'loan_status','purpose','dti', 'delinq_2yrs','open_acc','pub_rec',\n",
    "                'revol_bal','revol_util', 'total_pymnt', 'recoveries',\n",
    "                'inq_last_6mths', 'pct_tl_nvr_dlq', 'last_pymnt_d', 'earliest_cr_line']\n",
    "\n",
    "# Identify the type of each of these column\n",
    "float_cols = ['loan_amnt', 'funded_amnt', 'annual_inc',\n",
    "              'dti', 'revol_bal', 'delinq_2yrs', 'open_acc', 'pub_rec',\n",
    "              'total_pymnt', 'recoveries', 'inq_last_6mths']\n",
    "\n",
    "cat_cols = ['term', 'grade', 'emp_length', 'home_ownership',\n",
    "                    'verification_status', 'loan_status', 'purpose']\n",
    "\n",
    "perc_cols = ['int_rate', 'revol_util', 'pct_tl_nvr_dlq']\n",
    "\n",
    "date_cols = ['issue_d', 'last_pymnt_d', 'earliest_cr_line']\n",
    "\n",
    "# Ensure that we have types for every column\n",
    "assert set(cols_to_pick) - set(float_cols) - set(cat_cols) - set(perc_cols) - set(date_cols) == set([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeae8c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the columns of interest\n",
    "final_data = data_now[cols_to_pick].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae4ea3",
   "metadata": {},
   "source": [
    "#### Typecast the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46f659f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in float_cols:\n",
    "    final_data[i] = final_data[i].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e121903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_perc(x):\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    \n",
    "    # If x is already a float (or int), return it as is\n",
    "    if isinstance(x, (float, int)):\n",
    "        return float(x)\n",
    "    \n",
    "    x = x.rstrip()\n",
    "    if x.endswith('%'):\n",
    "        x = x[:-1]\n",
    "        \n",
    "    if x == '':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x)\n",
    "    \n",
    "for i in perc_cols:\n",
    "    final_data[i] = final_data[i].apply( clean_perc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1b56c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(x):\n",
    "    if pd.isnull(x):\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.strptime(x, \"%b-%y\").date()\n",
    "\n",
    "# Assuming final_data is your DataFrame and date_cols contains the date columns\n",
    "for i in date_cols:\n",
    "    final_data[i] = final_data[i].apply(clean_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dcf3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    final_data.loc[final_data[i].isnull(), i] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab893172",
   "metadata": {},
   "source": [
    "### Step 3 - Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18fb7751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 345 rows\n"
     ]
    }
   ],
   "source": [
    "# There are quite a few outliers, but the two most obvious ones to remove are in annual_inc, revol_bal Remove these.\n",
    "n_rows = len(final_data)\n",
    "final_data = final_data[final_data.annual_inc < 1000000]\n",
    "final_data = final_data[final_data.revol_bal < 400000]\n",
    "final_data = final_data[final_data.dti < 200]\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f582eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Remove all loans that are too recent to have been paid off or defaulted\n",
    "n_rows = len(final_data)\n",
    "final_data = final_data[final_data.loan_status.isin(['Fully Paid','Charged Off','Default'])]\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa9a0343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Only include loans issued since 2009\n",
    "n_rows = len(final_data)\n",
    "final_data = final_data[final_data.issue_d >= datetime.date(2009, 1, 1)]\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cef308",
   "metadata": {},
   "source": [
    "#### Outlier detection and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03703292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_and_limit_outliers(df, cols, z_threshold=3):\n",
    "    from scipy import stats\n",
    "    \n",
    "    \"\"\"\n",
    "    Flag outliers in specified columns using Z-score method and return the upper limit.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame\n",
    "        cols (list): List of columns to check for outliers\n",
    "        z_threshold (float): Z-score threshold for flagging outliers. Defaults to 3.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with additional columns to flag outliers\n",
    "        dict: Dictionary with upper limits for each column\n",
    "    \"\"\"\n",
    "    df_outliers = df.copy()\n",
    "    upper_limits = {}\n",
    "    \n",
    "    for col in cols:\n",
    "        col_mean = df_outliers[col].mean()\n",
    "        col_std = df_outliers[col].std()\n",
    "        \n",
    "        # Calculate upper limit for each column\n",
    "        upper_limit = col_mean + (z_threshold * col_std)\n",
    "        upper_limits[col] = upper_limit\n",
    "        \n",
    "        # Flag outliers in DataFrame\n",
    "        df_outliers[f\"{col}_outlier\"] = (df_outliers[col] > upper_limit).astype(int)\n",
    "        \n",
    "    return df_outliers, upper_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcef152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['annual_inc', 'inq_last_6mths', 'total_pymnt', 'open_acc']\n",
    "\n",
    "# Flag outliers and get upper limits\n",
    "df_outliers_flagged, upper_limits = flag_and_limit_outliers(final_data, columns_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af7ffde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_columns = ['annual_inc', 'inq_last_6mths', 'total_pymnt', 'open_acc']\n",
    "upper_limits_filtered = {k: upper_limits[k] for k in outliers_columns if k in upper_limits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68a27494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 31975 rows\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers based on upper limits\n",
    "n_rows = len(final_data)\n",
    "for col, upper_limit in upper_limits_filtered.items():\n",
    "    final_data = final_data[final_data[col] <= upper_limit]\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c5111",
   "metadata": {},
   "source": [
    "#### Drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbe8f605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 676 rows\n"
     ]
    }
   ],
   "source": [
    "# Deal with null values. We allow categorical variables to be null. OTHER than grade, which is a particularly important categorical.\n",
    "# All non-categorical variables must be non-null, and we drop rows that do not meet this requirement\n",
    "required_cols = set(cols_to_pick) - set(cat_cols) - set([\"id\"])\n",
    "required_cols.add(\"grade\")\n",
    "\n",
    "n_rows = len(final_data)\n",
    "final_data.dropna(subset = required_cols ,inplace=True)\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c076ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the columns selected will not be used directly in the model, but will be used to generate other features.\n",
    "\n",
    "# All categorical columns other than \"loan_status\" will be used as discrete features\n",
    "discrete_features = list(set(cat_cols) - set([\"loan_status\"]))\n",
    "\n",
    "# All numeric columns will be used as continuous features\n",
    "continuous_features = list(float_cols + perc_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d459eb9b",
   "metadata": {},
   "source": [
    "## WK2/Phase2 - Diagnostic and Descriptive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c403384",
   "metadata": {},
   "source": [
    "### Step 4 - Calculate returns for each loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6fd865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the names of the four returns we'll be calculating\n",
    "ret_cols = [\"ret_PESS\", \"ret_OPT\", \"ret_INTa\", \"ret_INTb\", \"ret_INTc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cfadbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1080 rows\n"
     ]
    }
   ],
   "source": [
    "## Remove all rows for loans that were paid back on the days they were issued\n",
    "final_data['loan_length'] = (final_data.last_pymnt_d - final_data.issue_d) / np.timedelta64(1, 'M')\n",
    "n_rows = len(final_data)\n",
    "final_data = final_data[final_data.loan_length != 0]\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8a7ee",
   "metadata": {},
   "source": [
    "#### Return Method 2 (pessimistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4154e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the return using a simple annualized profit margin\n",
    "# Pessimistic definition (method 2)\n",
    "final_data['term_num'] = final_data.term.str.extract('(\\d+)',expand=False).astype(int)\n",
    "final_data['ret_PESS'] = ( (final_data.total_pymnt - final_data.funded_amnt)\n",
    "                                            / final_data.funded_amnt ) * (12 / final_data['term_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9139ad7",
   "metadata": {},
   "source": [
    "#### Return Method 1 (optimistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1588234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that if a loan gives a positive return, we can immediately find a similar loan to invest in; \n",
    "#if the loan takes a loss, we use method 2 to compute the return\n",
    "final_data['ret_OPT'] = ( (final_data.total_pymnt - final_data.funded_amnt)\n",
    "                                            / final_data.funded_amnt ) * (12 / final_data['loan_length'])\n",
    "final_data.loc[final_data.ret_OPT < 0,'ret_OPT'] = final_data.ret_PESS[final_data.ret_OPT < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175526bc",
   "metadata": {},
   "source": [
    "#### Return Method 3 (re-investment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdd93728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_method_3(T, i):\n",
    "    '''\n",
    "    Given an investment time horizon (in months) and re-investment\n",
    "    interest rate, calculate the return of each loan\n",
    "    '''\n",
    "\n",
    "    # Assuming that the total amount paid back was paid at equal\n",
    "    # intervals during the duration of the loan, calculate the size of each of these installment\n",
    "    actual_installment = (final_data.total_pymnt - final_data.recoveries) / final_data['loan_length']\n",
    "\n",
    "    # Assuming the amount is immediately re-invested at the prime\n",
    "    # rate, find the total amount of money we'll have by the end of the loan\n",
    "    cash_by_end_of_loan = actual_installment * (1 - pow(1 + i, final_data.loan_length)) / ( 1 - (1 + i) )\n",
    "\n",
    "    cash_by_end_of_loan = cash_by_end_of_loan + final_data.recoveries\n",
    "\n",
    "    # Assuming that cash is then re-invested at the prime rate,\n",
    "    # with monthly re-investment, until T months from the start of the loan\n",
    "    remaining_months = T - final_data['loan_length']\n",
    "    final_return = cash_by_end_of_loan * pow(1 + i, remaining_months)\n",
    "\n",
    "    # Find the percentage return\n",
    "    return( (12/T) * ( ( final_return - final_data['funded_amnt'] ) / final_data['funded_amnt'] ) )\n",
    "\n",
    "final_data['ret_INTa'] = ret_method_3(5*12, 0.001)\n",
    "final_data['ret_INTb'] = ret_method_3(5*12, 0.0025)\n",
    "final_data['ret_INTc'] = ret_method_3(5*12, 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f205a87",
   "metadata": {},
   "source": [
    "## WK3/Phase3  - Predicting Default Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a82ae429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that, given a CVGridSearch object, finds the percentage difference between the best and worst scores\n",
    "\n",
    "def find_score_variation(cv_model):\n",
    "    all_scores = cv_model.cv_results_['mean_test_score']\n",
    "    return( np.abs((max(all_scores) - min(all_scores))) * 100 / max(all_scores) )\n",
    "\n",
    "    '''\n",
    "    which_min_score = np.argmin(all_scores)\n",
    "    \n",
    "    all_perc_diff = []\n",
    "    \n",
    "    try:\n",
    "        all_perc_diff.append( np.abs(all_scores[which_min_score - 1] - all_scores[which_min_score])*100 / min(all_scores) )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        all_perc_diff.append( np.abs(all_scores[which_min_score + 1] - all_scores[which_min_score])*100 / min(all_scores) )\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return ( np.mean(all_perc_diff) )\n",
    "    '''\n",
    "\n",
    "# Define a function that checks, given a CVGridSearch object, whether the optimal parameters lie on the edge of the search grid\n",
    "def find_opt_params_on_edge(cv_model):\n",
    "    out = False\n",
    "    \n",
    "    for i in cv_model.param_grid:\n",
    "        if cv_model.best_params_[i] in [ cv_model.param_grid[i][0], cv_model.param_grid[i][-1] ]:\n",
    "            out = True\n",
    "            break\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd73db39",
   "metadata": {},
   "source": [
    "### Define a default random seed and an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1281170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_seed = 1\n",
    "output_file = \"output_test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b464da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to print a line to our output file\n",
    "def dump_to_output(key, value):\n",
    "    with open(output_file, \"a\") as f:\n",
    "        f.write(\",\".join([str(default_seed), key, str(value)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657dc349",
   "metadata": {},
   "source": [
    "### Load the data and engineer the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b52ae76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the outcome\n",
    "final_data[\"outcome\"] = final_data.loan_status.isin([\"Charged Off\", \"Default\"])\n",
    "\n",
    "# Create a feature for the length of a person's credit history at the\n",
    "# time the loan is issued\n",
    "final_data['cr_hist'] = (final_data.issue_d - final_data.earliest_cr_line) / np.timedelta64(1, 'M')\n",
    "continuous_features.append('cr_hist')\n",
    "\n",
    "# Randomly assign each row to a training and test set. We do this now because we will be fitting a variety of models on various time periods,\n",
    "# and we would like every period to use the *same* training/test split\n",
    "np.random.seed(default_seed)\n",
    "final_data['train'] = np.random.choice([True, False], size = len(final_data), p = [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2eb8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kmeans = final_data.copy()\n",
    "data_kmeans['loan_status_binary'] = data_kmeans['outcome'].apply(lambda x: 1 if x == True else 0)\n",
    "continuous_features_kmeans = continuous_features.copy()\n",
    "continuous_features_kmeans.append('loan_status_binary')\n",
    "data_kmeans = data_kmeans[['int_rate', 'annual_inc','loan_amnt', 'dti','inq_last_6mths', 'open_acc', 'total_pymnt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39b3d83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_rate</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>total_pymnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.126838</td>\n",
       "      <td>0.189313</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>-0.803985</td>\n",
       "      <td>-0.711305</td>\n",
       "      <td>-1.115271</td>\n",
       "      <td>0.115949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.380691</td>\n",
       "      <td>-0.371253</td>\n",
       "      <td>-0.529553</td>\n",
       "      <td>-0.461659</td>\n",
       "      <td>1.774399</td>\n",
       "      <td>1.105701</td>\n",
       "      <td>-0.923345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168050</td>\n",
       "      <td>-0.595479</td>\n",
       "      <td>-0.862087</td>\n",
       "      <td>1.894352</td>\n",
       "      <td>0.531547</td>\n",
       "      <td>-0.105739</td>\n",
       "      <td>-1.340743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976089</td>\n",
       "      <td>1.506641</td>\n",
       "      <td>-0.239341</td>\n",
       "      <td>-1.244626</td>\n",
       "      <td>-0.711305</td>\n",
       "      <td>-0.711458</td>\n",
       "      <td>0.286870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.616187</td>\n",
       "      <td>-0.208689</td>\n",
       "      <td>0.803608</td>\n",
       "      <td>-0.038785</td>\n",
       "      <td>-0.711305</td>\n",
       "      <td>-0.307645</td>\n",
       "      <td>0.898727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   int_rate  annual_inc  loan_amnt       dti  inq_last_6mths  open_acc  \\\n",
       "0 -0.126838    0.189313   0.026687 -0.803985       -0.711305 -1.115271   \n",
       "1 -1.380691   -0.371253  -0.529553 -0.461659        1.774399  1.105701   \n",
       "2  0.168050   -0.595479  -0.862087  1.894352        0.531547 -0.105739   \n",
       "3  0.976089    1.506641  -0.239341 -1.244626       -0.711305 -0.711458   \n",
       "4  0.616187   -0.208689   0.803608 -0.038785       -0.711305 -0.307645   \n",
       "\n",
       "   total_pymnt  \n",
       "0     0.115949  \n",
       "1    -0.923345  \n",
       "2    -1.340743  \n",
       "3     0.286870  \n",
       "4     0.898727  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_st =  StandardScaler().fit_transform(data_kmeans) # this is an array\n",
    "\n",
    "# see few rows of standardized dataset\n",
    "pd.DataFrame(df_st, columns=data_kmeans.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4552d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 251224, 1: 204116, 2: 167308})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=3\n",
    "kmeans = KMeans(n_clusters=K, random_state=10).fit(df_st)\n",
    "labels = kmeans.labels_\n",
    "collections.Counter(labels) # show the number of occurences of each of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf1ee865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grade =  final_data.grade.to_numpy() # np_array\n",
    "K=3\n",
    "ltr2num = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6}\n",
    "table = np.zeros([7,K]) # row = letter grade, column = kmeans label\n",
    "for j in range(df_st.shape[0]):\n",
    "    table[ltr2num[grade[j]], labels[j]]+=1 # confusion matrix\n",
    "for i in range(7):\n",
    "    table[i,:] = np.round(table[i,:]*100/table[i,:].sum(), 1)\n",
    "\n",
    "df_temp = pd.DataFrame(table, columns = [0,1,2])\n",
    "# visulaize confusion matrix using heatmap\n",
    "grades = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "sns.heatmap(df_temp, annot=True, cmap='RdYlGn',  yticklabels=grades)\n",
    "plt.yticks(rotation=0, ha='right')  # ha is the horizontal alignment\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94ef4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['kmeans'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b75125de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical\n",
    "discrete_features.remove('grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a9bfa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous\n",
    "features_to_remove = ['funded_amnt'] #It cannot be removed until now\n",
    "continuous_features = [feature for feature in continuous_features if feature not in features_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0acfbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['home_ownership_RENT', 'purpose_credit_card', 'purpose_house', 'home_ownership_OTHER', 'cr_hist', 'verification_status_Verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39894f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix of features and outcomes, with dummies. Record the names of the dummies for later use\n",
    "X_continuous = final_data[continuous_features].values\n",
    "X_discrete = pd.get_dummies(final_data[discrete_features], dummy_na = True, prefix_sep = \"::\", drop_first = True)\n",
    "discrete_features_dummies = X_discrete.columns.tolist()\n",
    "discrete_features_dummies = [feature for feature in discrete_features_dummies if feature not in columns_to_remove]\n",
    "X_discrete = X_discrete.values\n",
    "\n",
    "X = np.concatenate( (X_continuous, X_discrete), axis = 1 )\n",
    "y = final_data.outcome.values\n",
    "\n",
    "train = final_data.train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4327a06f",
   "metadata": {},
   "source": [
    "### Prepare functions to fit and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b08279fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_imb(data_subset = np.array([True]*len(final_data)),\n",
    "                          n_samples_train = 20000,\n",
    "                          n_samples_test = 10000,\n",
    "                          feature_subset = None,\n",
    "                          date_range_train = (final_data.issue_d.min(), final_data.issue_d.max()),\n",
    "                          date_range_test = (final_data.issue_d.min(), final_data.issue_d.max()),\n",
    "                          random_state = default_seed):\n",
    "    \n",
    "    '''\n",
    "    This function prep the data for further analysis, but also takes care of the class imbalance situation\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    filter_train = ( train & (final_data.issue_d >= date_range_train[0]) &\n",
    "                            (final_data.issue_d <= date_range_train[1]) & data_subset ).values\n",
    "    filter_test = ( (train == False) & (final_data.issue_d >= date_range_test[0])\n",
    "                            & (final_data.issue_d <= date_range_test[1]) & data_subset ).values\n",
    "    \n",
    "    filter_train[ np.random.choice( np.where(filter_train)[0], size = filter_train.sum() \n",
    "                                   - n_samples_train, replace = False ) ] = False\n",
    "    filter_test[ np.random.choice( np.where(filter_test)[0], size = filter_test.sum() \n",
    "                                   - n_samples_test, replace = False ) ] = False\n",
    "    \n",
    "    # Get training data and labels\n",
    "    X_temp_train = X[filter_train, :]\n",
    "    y_temp_train = y[filter_train]\n",
    "    \n",
    "    # Separate majority and minority classes\n",
    "    X_majority = X_temp_train[y_temp_train == False]\n",
    "    X_minority = X_temp_train[y_temp_train == True]\n",
    "    y_majority = y_temp_train[y_temp_train == False]\n",
    "    y_minority = y_temp_train[y_temp_train == True]\n",
    "    \n",
    "    # Downsample majority class\n",
    "    X_majority_downsampled = X_majority[:len(X_minority)]\n",
    "    y_majority_downsampled = y_majority[:len(y_minority)]\n",
    "    \n",
    "    # Combine minority class with downsampled majority class\n",
    "    X_train_balanced = np.vstack((X_majority_downsampled, X_minority))\n",
    "    y_train_balanced = np.hstack((y_majority_downsampled, y_minority))\n",
    "    \n",
    "    # Prepare the test set\n",
    "    X_test = X[filter_test, :]\n",
    "    y_test = y[filter_test]\n",
    "    \n",
    "    # Feature selection if specified\n",
    "    if feature_subset != None:\n",
    "        cols = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n",
    "                                                     if j.split(\"::\")[0] in feature_subset]\n",
    "        X_train_balanced = X_train_balanced[:, cols]\n",
    "        X_test = X_test[:, cols]\n",
    "        \n",
    "    # Scale the variables\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    out = {'X_train': X_train_balanced, 'y_train': y_train_balanced, 'train_set': filter_train, \n",
    "           'X_test': X_test, 'y_test': y_test, 'test_set': filter_test}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d853ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_all(data_subset = np.array([True]*len(final_data)),\n",
    "                    n_samples_train = 20000,\n",
    "                    n_samples_test = 10000,\n",
    "                    feature_subset = None,\n",
    "                    date_range_train = (final_data.issue_d.min(), final_data.issue_d.max()),\n",
    "                    date_range_test = (final_data.issue_d.min(), final_data.issue_d.max()),\n",
    "                    random_state = default_seed):\n",
    "    '''\n",
    "    This function will prepare the data for classification or regression.\n",
    "    It expects the following parameters:\n",
    "      - data_subset: a numpy array with as many entries as rows in the\n",
    "                     dataset. Each entry should be True if that rowFdecisipn\n",
    "                     should be used, or False if it should be ignored\n",
    "      - n_samples_train: the total number of samples to be used for training.\n",
    "                         Will trigger an error if this number is larger than\n",
    "                         the number of rows available after all filters have\n",
    "                         been applied\n",
    "      - n_samples_test: as above for testing\n",
    "      - feature_subect: A list containing the names of the features to be\n",
    "                        used in the model. In None, all features in X are\n",
    "                        used\n",
    "      - date_range_train: a tuple containing two dates. All rows with loans\n",
    "                          issued outside of these two dates will be ignored in\n",
    "                          training\n",
    "      - date_range_test: as above for testing\n",
    "      - random_state: the random seed to use when selecting a subset of rows\n",
    "      \n",
    "    Note that this function assumes the data has a \"Train\" column, and will\n",
    "    select all training rows from the rows with \"True\" in that column, and all\n",
    "    the testing rows from those with a \"False\" in that column.\n",
    "    \n",
    "    This function returns a dictionary with the following entries\n",
    "      - X_train: the matrix of training data\n",
    "      - y_train: the array of training labels\n",
    "      - train_set: a Boolean vector with as many entries as rows in the data\n",
    "                  that denotes the rows that were used in the train set\n",
    "      - X_test: the matrix of testing data\n",
    "      - y_test: the array of testing labels\n",
    "      - test_set: a Boolean vector with as many entries as rows in the data\n",
    "                  that denotes the rows that were used in the test set\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Filter down the data to the required date range, and downsample\n",
    "    # as required\n",
    "#     print(\"sizes:\", train.shape[0], data.shape[0], data_subset.shape[0])\n",
    "    filter_train = ( train & (final_data.issue_d >= date_range_train[0]) &\n",
    "                            (final_data.issue_d <= date_range_train[1]) & data_subset ).values\n",
    "    filter_test = ( (train == False) & (final_data.issue_d >= date_range_test[0])\n",
    "                            & (final_data.issue_d <= date_range_test[1]) & data_subset ).values\n",
    "    \n",
    "    filter_train[ np.random.choice( np.where(filter_train)[0], size = filter_train.sum() \n",
    "                                   - n_samples_train, replace = False ) ] = False\n",
    "    filter_test[ np.random.choice( np.where(filter_test)[0], size = filter_test.sum() \n",
    "                                   - n_samples_test, replace = False ) ] = False\n",
    "    \n",
    "    # Prepare the training and test set\n",
    "    X_train = X[ filter_train , :]\n",
    "    X_test = X[ filter_test, :]\n",
    "    if feature_subset != None:\n",
    "        cols = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n",
    "                                                     if j.split(\"::\")[0] in feature_subset]\n",
    "        X_train = X_train[ : , cols ]\n",
    "        X_test = X_test[ : , cols ]\n",
    "        \n",
    "    y_train = y[ filter_train ]\n",
    "    y_test = y[ filter_test ]\n",
    "    \n",
    "    # Scale the variables\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # return training and testing data\n",
    "    out = {'X_train':X_train, 'y_train':y_train, 'train_set':filter_train, \n",
    "           'X_test':X_test, 'y_test':y_test, 'test_set':filter_test}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "becbbbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classification(model, data_dict,\n",
    "                          cv_parameters = {},\n",
    "                          model_name = None,\n",
    "                          random_state = default_seed,\n",
    "                          output_to_file = True,\n",
    "                          print_to_screen = True):\n",
    "    '''\n",
    "    This function will fit a classification model to data and print various evaluation\n",
    "    measures. It expects the following parameters\n",
    "      - model: an sklearn model object\n",
    "      - data_dict: the dictionary containing both training and testing data;\n",
    "                   returned by the prepare_data function\n",
    "      - cv_parameters: a dictionary of parameters that should be optimized\n",
    "                       over using cross-validation. Specifically, each named\n",
    "                       entry in the dictionary should correspond to a parameter,\n",
    "                       and each element should be a list containing the values\n",
    "                       to optimize over\n",
    "      - model_name: the name of the model being fit, for printouts\n",
    "      - random_state: the random seed to use\n",
    "      - output_to_file: if the results will be saved to the output file\n",
    "      - print_to_screen: if the results will be printed on screen\n",
    "    \n",
    "    If the model provided does not have a predict_proba function, we will\n",
    "    simply print accuracy diagnostics and return.\n",
    "    \n",
    "    If the model provided does have a predict_proba function, we first\n",
    "    figure out the optimal threshold that maximizes the accuracy and\n",
    "    print out accuracy diagnostics. We then print an ROC curve, sensitivity/\n",
    "    specificity curve, and calibration curve.\n",
    "    \n",
    "    This function returns a dictionary with the following entries\n",
    "      - model: the best fitted model\n",
    "      - y_pred: predictions for the test set\n",
    "      - y_pred_probs: probability predictions for the test set, if the model\n",
    "                      supports them\n",
    "      - y_pred_score: prediction scores for the test set, if the model does not \n",
    "                      output probabilities.\n",
    "    '''\n",
    "        \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # --------------------------\n",
    "    #   Step 1 - Load the data\n",
    "    # --------------------------\n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    \n",
    "    X_test = data_dict['X_test']\n",
    "    y_test = data_dict['y_test']\n",
    "    \n",
    "    filter_train = data_dict['train_set']    \n",
    "  \n",
    "    # --------------------------\n",
    "    #   Step 2 - Fit the model\n",
    "    # --------------------------\n",
    "\n",
    "    cv_model = GridSearchCV(model, cv_parameters)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    best_model = cv_model.best_estimator_\n",
    "    \n",
    "    if print_to_screen:\n",
    "\n",
    "        if model_name != None:\n",
    "            print(\"=========================================================\")\n",
    "            print(\"  Model: \" + model_name)\n",
    "            print(\"=========================================================\")\n",
    "\n",
    "        print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        print(\"Optimal parameters:\")\n",
    "        print(cv_model.best_params_)\n",
    "        print(\"\")\n",
    "    \n",
    "    # -------------------------------\n",
    "    #   Step 3 - Evaluate the model\n",
    "    # -------------------------------\n",
    "    \n",
    "    # If possible, make probability predictions\n",
    "    try:\n",
    "        y_pred_probs = best_model.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "        \n",
    "        probs_predicted = True\n",
    "    except:\n",
    "        probs_predicted = False\n",
    "    \n",
    "    # Make predictions; if we were able to find probabilities, use\n",
    "    # the threshold that maximizes the accuracy in the training set.\n",
    "    # If not, just use the learner's predict function\n",
    "    if probs_predicted:\n",
    "        y_train_pred_probs = best_model.predict_proba(X_train)[:,1]\n",
    "        fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_pred_probs)\n",
    "        \n",
    "        true_pos_train = tpr_train*(y_train.sum())\n",
    "        true_neg_train = (1 - fpr_train) *(1-y_train).sum()\n",
    "        \n",
    "        best_threshold_index = np.argmax(true_pos_train + true_neg_train)\n",
    "        best_threshold = 1 if best_threshold_index == 0 else thresholds_train[ best_threshold_index ]\n",
    "        \n",
    "        if print_to_screen:\n",
    "            print(\"Accuracy-maximizing threshold was: \" + str(best_threshold))\n",
    "        \n",
    "        y_pred = (y_pred_probs > best_threshold)\n",
    "    else:\n",
    "        y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    if print_to_screen:\n",
    "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred, target_names =['No default', 'Default'], digits = 4))\n",
    "\n",
    "    if print_to_screen:\n",
    "        if probs_predicted:        \n",
    "            plt.figure(figsize = (13, 4.5))\n",
    "            plt.subplot(2, 2, 1)\n",
    "\n",
    "            plt.title(\"ROC Curve (AUC = %0.2f)\"% roc_auc_score(y_test, y_pred_probs))\n",
    "            plt.plot(fpr, tpr, 'b')\n",
    "            plt.plot([0,1],[0,1],'r--')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "\n",
    "            plt.plot(thresholds, tpr, 'b', label = 'Sensitivity')\n",
    "            plt.plot(thresholds, 1 -fpr, 'r', label = 'Specificity')\n",
    "            plt.legend(loc = 'lower right')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.xlabel('Threshold')\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "\n",
    "            fp_0, mpv_0 = calibration_curve(y_test, y_pred_probs, n_bins = 10)\n",
    "            plt.plot([0,1], [0,1], 'k:', label='Perfectly calibrated')\n",
    "            plt.plot(mpv_0, fp_0, 's-')\n",
    "            plt.ylabel('Fraction of Positives')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.legend(loc ='upper left')\n",
    "            \n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.hist(y_pred_probs, range=(0, 1), bins=10, histtype=\"step\", lw=2)\n",
    "            plt.xlim([0,1]); plt.ylim([0,20000])\n",
    "            plt.xlabel('Mean Predicted Probability')\n",
    "            plt.ylabel('Count')\n",
    "            \n",
    "            #plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "    # Additional Score Check\n",
    "    if probs_predicted:\n",
    "        y_train_score = y_train_pred_probs\n",
    "    else:\n",
    "        y_train_score = best_model.decision_function(X_train)\n",
    "        \n",
    "#     tau, p_value = kendalltau(y_train_score, data.grade[filter_train])\n",
    "#     if print_to_screen:\n",
    "#         print(\"\")\n",
    "#         print(\"Similarity to LC grade ranking: \", tau)\n",
    "    \n",
    "    if probs_predicted:\n",
    "        brier_score = brier_score_loss(y_test, y_pred_probs)\n",
    "        if print_to_screen:\n",
    "            print(\"Brier score:\", brier_score)\n",
    "    \n",
    "    # Return the model predictions, and the\n",
    "    # test set\n",
    "    # -------------------------------------\n",
    "    out = {'model':best_model, 'y_pred_labels':y_pred}\n",
    "    \n",
    "    if probs_predicted:\n",
    "        out.update({'y_pred_probs':y_pred_probs})\n",
    "    else:\n",
    "        y_pred_score = best_model.decision_function(X_test)\n",
    "        out.update({'y_pred_score':y_pred_score})\n",
    "        \n",
    "    # Output results to file\n",
    "    # ----------------------\n",
    "    if probs_predicted and output_to_file:\n",
    "        # Check whether any of the CV parameters are on the edge of\n",
    "        # the search space\n",
    "        opt_params_on_edge = find_opt_params_on_edge(cv_model)\n",
    "        dump_to_output(model_name + \"::search_on_edge\", opt_params_on_edge)\n",
    "        if print_to_screen:\n",
    "            print(\"Were parameters on edge? : \" + str(opt_params_on_edge))\n",
    "        \n",
    "        # Find out how different the scores are for the different values\n",
    "        # tested for by cross-validation. If they're not too different, then\n",
    "        # even if the parameters are off the edge of the search grid, we should\n",
    "        # be ok\n",
    "        score_variation = find_score_variation(cv_model)\n",
    "        dump_to_output(model_name + \"::score_variation\", score_variation)\n",
    "        if print_to_screen:\n",
    "            print(\"Score variations around CV search grid : \" + str(score_variation))\n",
    "        \n",
    "        # Print out all the scores\n",
    "        dump_to_output(model_name + \"::all_cv_scores\", str(cv_model.cv_results_['mean_test_score']))\n",
    "        if print_to_screen:\n",
    "            print( str(cv_model.cv_results_['mean_test_score']) )\n",
    "        \n",
    "        # Dump the AUC to file\n",
    "        dump_to_output(model_name + \"::roc_auc\", roc_auc_score(y_test, y_pred_probs) )\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b7fbdc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regression(model, data_dict,\n",
    "                      cv_parameters = {},\n",
    "                      separate = False,\n",
    "                      model_name = None,\n",
    "                      random_state = default_seed,\n",
    "                      output_to_file = True,\n",
    "                      print_to_screen = True):\n",
    "    '''\n",
    "    This function will fit a regression model to data and print various evaluation\n",
    "    measures. It expects the following parameters\n",
    "      - model: an sklearn model object\n",
    "      - data_dict: the dictionary containing both training and testing data;\n",
    "                   returned by the prepare_data function\n",
    "      - separate: a Boolean variable indicating whether we fit models for\n",
    "                  defaulted and non-defaulted loans separately\n",
    "      - cv_parameters: a dictionary of parameters that should be optimized\n",
    "                       over using cross-validation. Specifically, each named\n",
    "                       entry in the dictionary should correspond to a parameter,\n",
    "                       and each element should be a list containing the values\n",
    "                       to optimize over\n",
    "      - model_name: the name of the model being fit, for printouts\n",
    "      - random_state: the random seed to use\n",
    "      - output_to_file: if the results will be saved to the output file\n",
    "      - print_to_screen: if the results will be printed on screen\n",
    "\n",
    "    This function returns a dictionary FOR EACH RETURN DEFINITION with the following entries\n",
    "      - model: the best fitted model\n",
    "      - predicted_return: prediction result based on the test set\n",
    "      - predicted_regular_return: prediction result for non-defaulted loans (valid if separate == True)\n",
    "      - predicted_default_return: prediction result for defaulted loans (valid if separate == True)\n",
    "      - r2_scores: the testing r2_score(s) for the best fitted model\n",
    "    '''\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # --------------------------\n",
    "    #   Step 1 - Load the data\n",
    "    # --------------------------\n",
    "\n",
    "    col_list = ['ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb', 'ret_INTc']\n",
    "\n",
    "    X_train = data_dict['X_train']\n",
    "    filter_train = data_dict['train_set']\n",
    "\n",
    "    X_test = data_dict['X_test']\n",
    "    filter_test = data_dict['test_set']\n",
    "    out = {}\n",
    "\n",
    "    for ret_col in col_list:\n",
    "\n",
    "        #y_train = data.loc[filter_train, ret_col].as_matrix()\n",
    "        #y_test = data.loc[filter_test, ret_col].as_matrix()\n",
    "        y_train = data.loc[filter_train, ret_col].to_numpy()\n",
    "        y_test = data.loc[filter_test, ret_col].to_numpy()\n",
    "\n",
    "        # --------------------------\n",
    "        #   Step 2 - Fit the model\n",
    "        # --------------------------\n",
    "\n",
    "        if separate:\n",
    "            outcome_train = data.loc[filter_train, 'outcome']\n",
    "            outcome_test = data.loc[filter_test, 'outcome']\n",
    "\n",
    "            # Train two separate regressors for defaulted and non-defaulted loans\n",
    "            X_train_0 = X_train[outcome_train == False]\n",
    "            y_train_0 = y_train[outcome_train == False]\n",
    "            X_test_0 = X_test[outcome_test == False]\n",
    "            y_test_0 = y_test[outcome_test == False]\n",
    "\n",
    "            X_train_1 = X_train[outcome_train == True]\n",
    "            y_train_1 = y_train[outcome_train == True]\n",
    "            X_test_1 = X_test[outcome_test == True]\n",
    "            y_test_1 = y_test[outcome_test == True]\n",
    "\n",
    "            cv_model_0 = GridSearchCV(model, cv_parameters, scoring='r2')\n",
    "            cv_model_1 = GridSearchCV(model, cv_parameters, scoring='r2')\n",
    "\n",
    "            start_time = time.time()\n",
    "            cv_model_0.fit(X_train_0, y_train_0)\n",
    "            cv_model_1.fit(X_train_1, y_train_1)\n",
    "            end_time = time.time()\n",
    "\n",
    "            best_model_0 = cv_model_0.best_estimator_\n",
    "            best_model_1 = cv_model_1.best_estimator_\n",
    "\n",
    "            if print_to_screen:\n",
    "\n",
    "                if model_name != None:\n",
    "                    print(\"=========================================================\")\n",
    "                    print(\"  Model: \" + model_name + \"  Return column: \" + ret_col)\n",
    "                    print(\"=========================================================\")\n",
    "\n",
    "                print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "                print(\"Optimal parameters:\")\n",
    "                print(\"model_0:\",cv_model_0.best_params_, \"model_1\",cv_model_1.best_params_)\n",
    "\n",
    "            predicted_regular_return = best_model_0.predict(X_test)\n",
    "            predicted_default_return = best_model_1.predict(X_test)\n",
    "\n",
    "            if print_to_screen:\n",
    "                print(\"\")\n",
    "                print(\"Testing r2 scores:\")\n",
    "            # Here we use different testing set to report the performance\n",
    "            test_scores = {'model_0':r2_score(y_test_0,best_model_0.predict(X_test_0)),\n",
    "                              'model_1':r2_score(y_test_1,best_model_1.predict(X_test_1))}\n",
    "            if print_to_screen:\n",
    "                print(\"model_0:\", test_scores['model_0'])\n",
    "                print(\"model_1:\", test_scores['model_1'])\n",
    "\n",
    "            cv_objects = {'model_0':cv_model_0, 'model_1':cv_model_1}\n",
    "            out[ret_col] = { 'model_0':best_model_0, 'model_1':best_model_1, 'predicted_regular_return':predicted_regular_return,\n",
    "                      'predicted_default_return':predicted_default_return,'r2_scores':test_scores }\n",
    "\n",
    "        else:\n",
    "            cv_model = GridSearchCV(model, cv_parameters, scoring='r2')\n",
    "\n",
    "            start_time = time.time()\n",
    "            cv_model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "\n",
    "            best_model = cv_model.best_estimator_\n",
    "\n",
    "            if print_to_screen:\n",
    "                if model_name != None:\n",
    "                    print(\"=========================================================\")\n",
    "                    print(\"  Model: \" + model_name + \"  Return column: \" + ret_col)\n",
    "                    print(\"=========================================================\")\n",
    "\n",
    "                print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "                print(\"Optimal parameters:\")\n",
    "                print(cv_model.best_params_)\n",
    "\n",
    "            predicted_return = best_model.predict(X_test)\n",
    "            test_scores = {'model':r2_score(y_test,predicted_return)}\n",
    "            if print_to_screen:\n",
    "                print(\"\")\n",
    "                print(\"Testing r2 score:\", test_scores['model'])\n",
    "\n",
    "            cv_objects = {'model':cv_model}\n",
    "            out[ret_col] = {'model':best_model, 'predicted_return':predicted_return, 'r2_scores':r2_score(y_test,predicted_return)}\n",
    "\n",
    "        # Output the results to a file\n",
    "        if output_to_file:\n",
    "            for i in cv_objects:\n",
    "                # Check whether any of the CV parameters are on the edge of\n",
    "                # the search space\n",
    "                opt_params_on_edge = find_opt_params_on_edge(cv_objects[i])\n",
    "                dump_to_output(model_name + \"::\" + ret_col + \"::search_on_edge\", opt_params_on_edge)\n",
    "                if print_to_screen:\n",
    "                    print(\"Were parameters on edge (\" + i + \") : \" + str(opt_params_on_edge))\n",
    "\n",
    "                # Find out how different the scores are for the different values\n",
    "                # tested for by cross-validation. If they're not too different, then\n",
    "                # even if the parameters are off the edge of the search grid, we should\n",
    "                # be ok\n",
    "                score_variation = find_score_variation(cv_objects[i])\n",
    "                dump_to_output(model_name + \"::\" + ret_col + \"::score_variation\", score_variation)\n",
    "                if print_to_screen:\n",
    "                    print(\"Score variations around CV search grid (\" + i + \") : \" + str(score_variation))\n",
    "\n",
    "                # Print out all the scores\n",
    "                dump_to_output(model_name + \"::all_cv_scores\", str(cv_objects[i].cv_results_['mean_test_score']))\n",
    "                if print_to_screen:\n",
    "                    print(\"All test scores : \" + str(cv_objects[i].cv_results_['mean_test_score']) )\n",
    "\n",
    "                # Dump the AUC to file\n",
    "                dump_to_output( model_name + \"::\" + ret_col + \"::r2\", test_scores[i] )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceaf510",
   "metadata": {},
   "source": [
    "### Feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c02d3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_features = [i for i in discrete_features + continuous_features if i not in [\"grade\", \"int_rate\", \"installment\"]]\n",
    "final_features = [i for i in discrete_features + continuous_features]\n",
    "all_features = pd.Series(continuous_features + discrete_features_dummies)\n",
    "idx = [i for i, j in enumerate(continuous_features + discrete_features_dummies)\n",
    "                                                     if j.split(\"::\")[0] in final_features]\n",
    "\n",
    "## useful when choosing the most significant features\n",
    "selected_features = all_features[idx]\n",
    "selected_features.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d1ee63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3698, 3698)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Process data here: This one is for class imbalance conditions\n",
    "data_dict = prepare_data_imb(data_subset = np.array([True]*len(final_data)), feature_subset = final_features)\n",
    "\n",
    "# Checking the number of Trues and Falses in the y_train from the provided data dictionary\n",
    "true_count = np.sum(data_dict['y_train'])\n",
    "false_count = len(data_dict['y_train']) - true_count\n",
    "true_count, false_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6bd75680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3698, 16302)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Process data here: This does not take care of class imbalance\n",
    "data_dict_reg = prepare_data_all(data_subset = np.array([True]*len(final_data)), feature_subset = final_features)\n",
    "\n",
    "# Checking the number of Trues and Falses in the y_train from the provided data dictionary\n",
    "true_count = np.sum(data_dict_reg['y_train'])\n",
    "false_count = len(data_dict_reg['y_train']) - true_count\n",
    "true_count, false_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04554ef7",
   "metadata": {},
   "source": [
    "### $l_1$ penalized logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "180423b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "  Model: l1 Penalized Logistic Regression\n",
      "=========================================================\n",
      "Fit time: 443.37 seconds\n",
      "Optimal parameters:\n",
      "{'C': 464.15888336127773}\n",
      "\n",
      "Accuracy-maximizing threshold was: 0.3752804021744568\n",
      "Accuracy:  0.9847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No default     0.9905    0.9908    0.9907      8188\n",
      "     Default     0.9585    0.9570    0.9577      1812\n",
      "\n",
      "    accuracy                         0.9847     10000\n",
      "   macro avg     0.9745    0.9739    0.9742     10000\n",
      "weighted avg     0.9847    0.9847    0.9847     10000\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calibration_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38812\\292799732.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ml1_logistic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'saga'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcv_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m l1_logistic_all = fit_classification(l1_logistic, data_dict,\n\u001b[0m\u001b[0;32m      5\u001b[0m                       cv_parameters = cv_parameters, model_name = \"l1 Penalized Logistic Regression\")\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_38812\\1592163500.py\u001b[0m in \u001b[0;36mfit_classification\u001b[1;34m(model, data_dict, cv_parameters, model_name, random_state, output_to_file, print_to_screen)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[0mfp_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmpv_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalibration_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'k:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Perfectly calibrated'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmpv_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'calibration_curve' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1300x450 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run the following the first time through\n",
    "l1_logistic = LogisticRegression(penalty = 'l1',solver='saga', max_iter=10000, n_jobs=-1)\n",
    "cv_parameters = {\"C\":np.logspace(0, 6, num = 10)}\n",
    "l1_logistic_all = fit_classification(l1_logistic, data_dict,\n",
    "                      cv_parameters = cv_parameters, model_name = \"l1 Penalized Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot top 3 features with the most positive (and negative) weights \n",
    "top_and_bottom_idx = list(np.argsort(l1_logistic_all['model'].coef_)[0,:3]) + list(np.argsort(l1_logistic_all['model'].coef_)[0,-3:])\n",
    "bplot = pd.Series(l1_logistic_all['model'].coef_[0,top_and_bottom_idx])\n",
    "xticks = selected_features[top_and_bottom_idx]\n",
    "p1 = bplot.plot(kind='bar',rot=-30,ylim=(-5,5))\n",
    "p1.set_xticklabels(xticks)\n",
    "plt.title('Most significant features of l1_logistic_all')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e10c0",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a556165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the following the first time through\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "cv_parameters = {'min_samples_leaf':[1, 2, 3, 5, 8, 13, 17, 20, 40], 'n_estimators': [35, 60, 80, 100, 150] }\n",
    "rf_all = fit_classification(rf, data_dict, cv_parameters = cv_parameters, model_name = \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5127e",
   "metadata": {},
   "source": [
    "### Build and Test Regression Models for returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8e28c",
   "metadata": {},
   "source": [
    "### Lasso-Lars regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Regressor\n",
    "cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n",
    "reg_lasso = fit_regression(linear_model.LassoLars(), data_dict_reg,  \n",
    "               cv_parameters = cv_parameters, separate = False, model_name = \"Lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebe21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Models\n",
    "cv_parameters = {'alpha': np.logspace(-8, -1, num = 8) }\n",
    "reg_separate = fit_regression(linear_model.LassoLars(), data_dict_reg,  \n",
    "               cv_parameters = cv_parameters, separate = True, model_name = \"Lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2723c",
   "metadata": {},
   "source": [
    "### Save the models in one file or save the whole session in a dill file\n",
    "Some of the models take long time to train. You may put your models in a dictionary and save it by running: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c646702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all time-consuming models in one dict_ \n",
    "models_to_save = {}\n",
    "models_to_save['reg_lasso'] = reg_lasso\n",
    "models_to_save['reg_separate'] = reg_separate\n",
    "models_to_save['l1_logistic_all'] = l1_logistic_all\n",
    "models_to_save['rf_all'] = rf_all\n",
    "\n",
    "# os.path.abspath(os.getcwd()) # get current directory\n",
    "filename = './week4_saved_models'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(models_to_save, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f2b9e5",
   "metadata": {},
   "source": [
    "## WK4/Phase4 - Picking Loans using Regression of Loan Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50b0c0",
   "metadata": {},
   "source": [
    "### Test investment strategies\n",
    "Now we test several investment strategies using the learning models above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_investments(data_dict,\n",
    "                        classifier = None,\n",
    "                        regressor = None,\n",
    "                        strategy = 'Random',\n",
    "                        num_loans = 1000,\n",
    "                        random_state = default_seed,\n",
    "                        output_to_file = True):\n",
    "    '''\n",
    "    This function tests a variety of investment methodologies and their returns.\n",
    "    It will run its tests on the loans defined by the test_set element of the data\n",
    "    dictionary.\n",
    "\n",
    "    It is currently able to test four strategies\n",
    "      - random: invest in a random set of loans\n",
    "      - ranking: score each loan by probability of default, and only invest\n",
    "                 in the \"safest\" loans (i.e., those with the lowest probabilities\n",
    "                 of default)\n",
    "      - regression: train a single regression model to predict the expected return\n",
    "                    of loans in the past. Then, for loans we could invest in, simply\n",
    "                    rank them by their expected returns and invest in that order.\n",
    "      - two-stage: train two regression models to predict the expected return of\n",
    "                   defaulted loans and non-defaulted loans in the training set. Then,\n",
    "                   for each potential loan we could invest in, predict the probability\n",
    "                   the loan will default, its return if it doesn't default and its\n",
    "                   return if it does. Then, calculate a weighted combination of\n",
    "                   the latter using the former to find a predicted return. Rank the\n",
    "                   loans by this expected return, and invest in that order\n",
    "      - knapsack: \n",
    "\n",
    "    It expects the following parameters\n",
    "      - data: the data set we are using now\n",
    "      - data_dict: the dictionary containing both training and testing data;\n",
    "                   returned by the prepare_data function\n",
    "      - classifier: a fitted model object which is returned by the fit_classification function.\n",
    "      - regressor: a fitted model object which is returned by the fit_regression function.\n",
    "      - strategy: the name of the strategy; one of the three listed above\n",
    "      - num_loans: the number of loans to be included in the test portfolio\n",
    "      - num_samples: the number of random samples used to compute average return ()\n",
    "      - random_state: the random seed to use when selecting a subset of rows\n",
    "      - output_to_file: if the results will be saved to the output file\n",
    "\n",
    "    The function returns a dictionary FOR EACH RETURN DEFINITION with the following entries\n",
    "      - strategy: the name of the strategy\n",
    "      - average return: the return of the strategy based on the testing set\n",
    "      - test data: the updated Dataframe of testing data. Useful in the optimization section\n",
    "    '''\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Retrieve the rows that were used to train and test  the\n",
    "    # classification model\n",
    "    train_set = data_dict['train_set']\n",
    "    test_set = data_dict['test_set']\n",
    "\n",
    "    col_list = ['ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb', 'ret_INTc']\n",
    "\n",
    "    # Create a dataframe for testing, including the score\n",
    "    data_test = data.loc[test_set,:]\n",
    "    out = {}\n",
    "\n",
    "    for ret_col in col_list:\n",
    "\n",
    "        if strategy == 'Random':\n",
    "            # Randomize the order of the rows in the datframe\n",
    "            data_test = data_test.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "            # Select num_loans to invest in\n",
    "            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n",
    "\n",
    "            # Find the average return for these loans\n",
    "            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n",
    "\n",
    "            # Return\n",
    "            out[ret_col] = {'strategy':strategy, 'average return':ret_test}\n",
    "\n",
    "            # Dump the strategy performance to file\n",
    "            if output_to_file:\n",
    "                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n",
    "\n",
    "            continue\n",
    "\n",
    "        elif strategy == 'Regression':\n",
    "\n",
    "            colname = 'predicted_return_' + ret_col\n",
    "\n",
    "            data_test[colname] = regressor[ret_col]['predicted_return']\n",
    "\n",
    "            # Sort the loans by predicted return\n",
    "            data_test = data_test.sort_values(by=colname, ascending = False).reset_index(drop = True)\n",
    "\n",
    "            # Pick num_loans loans\n",
    "            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n",
    "\n",
    "            # Find their return\n",
    "            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n",
    "\n",
    "            # Return\n",
    "            out[ret_col] = {'strategy':strategy, 'average return':ret_test, 'test data':data_test}\n",
    "\n",
    "            # Dump the strategy performance to file\n",
    "            if output_to_file:\n",
    "                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n",
    "\n",
    "            continue\n",
    "\n",
    "        # Get the predicted scores, if the strategy is not Random or just Regression\n",
    "        try:\n",
    "            y_pred_score = classifier['y_pred_probs']\n",
    "        except:\n",
    "            y_pred_score = classifier['y_pred_score']\n",
    "\n",
    "        data_test['score'] = y_pred_score\n",
    "\n",
    "\n",
    "        if strategy == 'Ranking':\n",
    "            # Sort the test data by the score\n",
    "            data_test = data_test.sort_values(by='score').reset_index(drop = True)\n",
    "\n",
    "            # Select num_loans to invest in\n",
    "            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n",
    "\n",
    "            # Find the average return for these loans\n",
    "            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n",
    "\n",
    "            # Return\n",
    "            out[ret_col] = {'strategy':strategy, 'average return':ret_test}\n",
    "\n",
    "            # Dump the strategy performance to file\n",
    "            if output_to_file:\n",
    "                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "        elif strategy == 'Two-stage':\n",
    "\n",
    "            # Load the predicted returns\n",
    "            data_test['predicted_regular_return'] = regressor[ret_col]['predicted_regular_return']\n",
    "            data_test['predicted_default_return'] = regressor[ret_col]['predicted_default_return']\n",
    "\n",
    "            # Compute expectation\n",
    "            colname = 'predicted_return_' + ret_col\n",
    "\n",
    "            data_test[colname] = ( (1-data_test.score)*data_test.predicted_regular_return +\n",
    "                                             data_test.score*data_test.predicted_default_return )\n",
    "\n",
    "            # Sort the loans by predicted return\n",
    "            data_test = data_test.sort_values(by=colname, ascending = False).reset_index(drop = True)\n",
    "\n",
    "            # Pick num_loans loans\n",
    "            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n",
    "\n",
    "            # Find their return\n",
    "            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n",
    "\n",
    "            # Return\n",
    "            out[ret_col] = {'strategy':strategy, 'average return':ret_test, 'test data':data_test}\n",
    "\n",
    "            # Dump the strategy performance to file\n",
    "            if output_to_file:\n",
    "                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n",
    "\n",
    "            continue\n",
    "\n",
    "        elif strategy == 'Greedy':\n",
    "\n",
    "            # Sort the loans by return-to-risk ratio:\n",
    "            temp1 = regressor[\"ret_INTc\"]['predicted_return']\n",
    "            #temp1 = data_test.ret_INTc.to_numpy() # return\n",
    "            temp2 = data_test['score'].to_numpy() # default probability\n",
    "            data_test['ratio'] = temp1/temp2\n",
    "            data_test = data_test.sort_values(by='ratio', ascending = False).reset_index(drop = True)\n",
    "\n",
    "            # Pick num_loans loans\n",
    "            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n",
    "\n",
    "            # Find their return\n",
    "            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n",
    "\n",
    "            # Return\n",
    "            out[ret_col] = {'strategy':strategy, 'average return':ret_test}\n",
    "\n",
    "            # Dump the strategy performance to file\n",
    "            if output_to_file:\n",
    "                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n",
    "\n",
    "            continue\n",
    "            \n",
    "        elif strategy == 'KMeans':\n",
    "            \n",
    "            # Extract unique kmeans values\n",
    "            kmeans_values = data_test['kmeans'].unique()\n",
    "\n",
    "            for kmean_val in kmeans_values:\n",
    "\n",
    "                # Subset data based on current kmean value\n",
    "                data_subset = data_test[data_test['kmeans'] == kmean_val].copy()\n",
    "\n",
    "                # Reset the index of the subset for direct indexing\n",
    "                data_subset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Filter the predicted returns to match the data_subset length\n",
    "                predicted_regular_return_subset = regressor[ret_col]['predicted_regular_return'][data_subset.index]\n",
    "                predicted_default_return_subset = regressor[ret_col]['predicted_default_return'][data_subset.index]\n",
    "\n",
    "                # Load the predicted returns\n",
    "                data_subset['predicted_regular_return'] = predicted_regular_return_subset\n",
    "                data_subset['predicted_default_return'] = predicted_default_return_subset\n",
    "\n",
    "                # Compute expectation\n",
    "                colname = 'predicted_return_' + ret_col\n",
    "\n",
    "                data_subset[colname] = ((1-data_subset.score) * data_subset.predicted_regular_return +\n",
    "                                        data_subset.score * data_subset.predicted_default_return)\n",
    "\n",
    "                # Sort the loans by predicted return\n",
    "                data_subset = data_subset.sort_values(by=colname, ascending = False).reset_index(drop = True)\n",
    "\n",
    "                # Pick num_loans loans\n",
    "                pf_test = data_subset[['funded_amnt',ret_col]].iloc[:num_loans]\n",
    "\n",
    "                # Find their return\n",
    "                ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n",
    "\n",
    "                # Return\n",
    "                out_key = ret_col + \"_kmean_\" + str(kmean_val)  # Use a unique key for each kmean value\n",
    "                out[out_key] = {'strategy':strategy, 'kmean':kmean_val, 'average return':ret_test, 'test data':data_subset}\n",
    "\n",
    "                # Dump the strategy performance to file\n",
    "                if output_to_file:\n",
    "                    dump_to_output(strategy + \",\" + ret_col + \"_kmean_\" + str(kmean_val) + \"::average return\", ret_test)\n",
    "\n",
    "            continue\n",
    "\n",
    "        elif strategy == 'Crystal-ball':\n",
    "\n",
    "            # Sort the loans by realized return\n",
    "            data_test = data_test.sort_values(by=ret_col, ascending = False).reset_index(drop = True)\n",
    "\n",
    "            # Pick num_loans loans\n",
    "            pf_test = data_test[['funded_amnt',ret_col]].iloc[:num_loans]\n",
    "\n",
    "            # Find their return\n",
    "            ret_test = np.dot(pf_test[ret_col],pf_test.funded_amnt)/np.sum(pf_test.funded_amnt)\n",
    "\n",
    "            # Return\n",
    "            out[ret_col] = {'strategy':strategy, 'average return':ret_test}\n",
    "\n",
    "            # Dump the strategy performance to file\n",
    "            if output_to_file:\n",
    "                dump_to_output(strategy + \",\" + ret_col + \"::average return\", ret_test )\n",
    "\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            return 'Not a valid strategy'\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99228aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = data_dict_reg['train_set']\n",
    "test_set = data_dict_reg['test_set']\n",
    "\n",
    "# Create a dataframe for testing, including the score\n",
    "data_test1 = final_data.loc[test_set,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a063a55",
   "metadata": {},
   "source": [
    "### Implement the test strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029d633",
   "metadata": {},
   "source": [
    "#### Random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f02787",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['ret_PESS', 'ret_OPT', 'ret_INTa', 'ret_INTb', 'ret_INTc']\n",
    "test_strategy = 'Random'\n",
    "\n",
    "print('strategy:',test_strategy)   \n",
    "strat_random = test_investments(data_dict_reg, strategy = test_strategy, \n",
    "                            num_loans = 100, output_to_file = False, random_state = 1)\n",
    "for ret_col in col_list:\n",
    "    print(ret_col + ': ' + str(strat_random[ret_col]['average return']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb20ef",
   "metadata": {},
   "source": [
    "#### Ranking  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b84c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy = 'Ranking'\n",
    "\n",
    "print('strategy:',test_strategy)\n",
    "strat_rank = test_investments(data_dict_reg, classifier=l1_logistic_all, strategy = test_strategy, \n",
    "                        num_loans = 100, output_to_file = False)\n",
    "\n",
    "for ret_col in col_list:\n",
    "    print(ret_col + ': ' + str(strat_rank[ret_col]['average return']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcda420",
   "metadata": {},
   "source": [
    "#### Regression    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy = 'Regression'\n",
    "\n",
    "print('strategy:',test_strategy)\n",
    "strat_reg = test_investments(data_dict_reg, regressor = reg_lasso, strategy = test_strategy, \n",
    "                        num_loans = 100)\n",
    "for ret_col in col_list:\n",
    "    print(ret_col + ': ' + str(strat_reg[ret_col]['average return']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6041c",
   "metadata": {},
   "source": [
    "#### Two Stage Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy = 'Two-stage'\n",
    "\n",
    "print('strategy:',test_strategy)\n",
    "two_stage = test_investments(data_dict_reg, classifier = l1_logistic_all, regressor = reg_separate, \n",
    "                             strategy = test_strategy, num_loans = 100)\n",
    "\n",
    "for ret_col in col_list:\n",
    "    print(ret_col + ': ' + str(two_stage[ret_col]['average return']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360c3be",
   "metadata": {},
   "source": [
    "#### New Greedy Rule: sort the loans by return-to-risk ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy = 'Greedy'\n",
    "print('strategy:',test_strategy)\n",
    "strat_rank = test_investments(data_dict_reg, classifier = l1_logistic_all, regressor = reg_lasso, strategy = test_strategy, \n",
    "                        num_loans = 100, output_to_file = False)\n",
    "\n",
    "for ret_col in col_list:\n",
    "    print(ret_col + ': ' + str(strat_rank[ret_col]['average return']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ddb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd1d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09eb7d57",
   "metadata": {},
   "source": [
    "#### New KMeans Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy = 'KMeans'\n",
    "print('strategy:', test_strategy)\n",
    "kmeans_strategy = test_investments(data_dict_reg, classifier = l1_logistic_all, regressor = reg_separate, \n",
    "                             strategy = test_strategy, num_loans = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23dfd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique kmeans values from the test data\n",
    "test_data_subset = data.loc[data_dict1213_reg['test_set']]\n",
    "kmeans_values = test_data_subset['kmeans'].unique()\n",
    "\n",
    "# Loop through each return column\n",
    "for ret_col in col_list:\n",
    "    for kmean_val in kmeans_values:\n",
    "        key = ret_col + \"_kmean_\" + str(kmean_val)\n",
    "        if key in kmeans_strategy:\n",
    "            print(key + ': ' + str(kmeans_strategy[key]['average return']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea2fc26",
   "metadata": {},
   "source": [
    "### Step 5 - Sensitivity test of portfolio size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sensitivity = []\n",
    "\n",
    "# Vary the portfolio size from 10 to 300 in increments of 10\n",
    "for num_loans in list(range(10,500,10)):\n",
    "    reg_0 = test_investments(data_dict1213_reg, regressor=reg_separate1213, classifier=l1_logistic1213, \n",
    "                             strategy='Two-stage', num_loans=num_loans)\n",
    "    result_sensitivity.append(reg_0['ret_INTc']['average return'])\n",
    "\n",
    "result_sensitivity = np.array(result_sensitivity) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b269428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size (width, height) in inches\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Plot using seaborn\n",
    "sns.pointplot(x=np.array(list(range(10, 500, 10))), y=result_sensitivity)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add a red dotted line for the average return\n",
    "average_return = np.mean(result_sensitivity)\n",
    "plt.axhline(y=average_return, color='red', linestyle='--', label=f\"Average Return: {average_return:.2f}%\")\n",
    "\n",
    "# Remove top and right borders\n",
    "sns.despine()\n",
    "\n",
    "# Set y-axis and x-axis labels with font size\n",
    "plt.ylabel('Investment Return (%)', size=20)\n",
    "plt.xlabel('Portfolio Size', size=20)\n",
    "\n",
    "# Add title to the plot\n",
    "plt.title(\"Investment Returns using Two-stage Strategy and ret_INTc Metric\", size=25)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio sizes to test\n",
    "portfolio_sizes = list(range(10, 500, 10))\n",
    "\n",
    "# Storing average returns for each kmean cluster\n",
    "returns_per_cluster = {}\n",
    "\n",
    "# Loop through portfolio sizes\n",
    "for num_loans in portfolio_sizes:\n",
    "    \n",
    "    # Get investment results using the 'KMeans' strategy\n",
    "    kmeans_results = test_investments(data_dict1213_reg, classifier=l1_logistic1213, regressor=reg_separate1213, \n",
    "                                      strategy='KMeans', num_loans=num_loans)\n",
    "    \n",
    "    # Loop through each kmeans cluster for ret_INTc\n",
    "    for key in kmeans_results:\n",
    "        if \"ret_INTc_kmean\" in key:\n",
    "            cluster_num = key.split(\"_\")[-1]\n",
    "            if cluster_num not in returns_per_cluster:\n",
    "                returns_per_cluster[cluster_num] = []\n",
    "            returns_per_cluster[cluster_num].append(kmeans_results[key]['average return'] * 100)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Colors for each cluster's returns\n",
    "colors = sns.color_palette(\"tab10\", len(returns_per_cluster))\n",
    "\n",
    "# Plot each cluster's returns\n",
    "for i, (cluster_num, returns) in enumerate(returns_per_cluster.items()):\n",
    "    sns.lineplot(x=portfolio_sizes, y=returns, label=f\"Cluster {cluster_num}\", color=colors[i], linewidth=2.5)\n",
    "    \n",
    "    # Plot average return for this cluster\n",
    "    avg_return = np.mean(returns)\n",
    "    plt.axhline(y=avg_return, color=colors[i], linestyle='--', label=f\"Average Return Cluster {cluster_num}: {avg_return:.2f}%\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xticks(rotation=45)\n",
    "sns.despine()\n",
    "plt.ylabel('Investment Return (%)', size=20)\n",
    "plt.xlabel('Portfolio Size', size=20)\n",
    "plt.title(\"Investment Returns for ret_INTc using KMeans Strategy per Cluster\", size=25)\n",
    "plt.legend(title=\"KMeans Cluster and Averages\", loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451a983a",
   "metadata": {},
   "source": [
    "## WK5/Phase5 - Optimization Models for Picking Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at distribution in date to decide the size of train and test set splitted by time\n",
    "final_data['issue_d'].hist(xrot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95bea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fund out cut off date to divide the data into ~70% traininig data and ~30% testing data\n",
    "date_threshold = np.quantile(final_data['issue_d'],5/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a03726",
   "metadata": {},
   "source": [
    "### 5.3 Optimization\n",
    "\n",
    "In this section, we implement three different optimization models. To illustrate and compare these models we will only use the M1-PESS definition and the predicted returns from the previously tested two-stage strategy.\n",
    "\n",
    "### Three optimization models to picks loans\n",
    "\n",
    "#### 5.3.1 Directly maximize total profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34450417",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_col = 'ret_INTc'\n",
    "test_pool = two_stage[ret_col]['test data']\n",
    "num_var = test_pool.shape[0]\n",
    "num_loans = 10\n",
    "\n",
    "## first define cost vector\n",
    "c = np.zeros(num_var) # cost vector\n",
    "for i in range(num_var):\n",
    "    c[i] = test_pool['predicted_return_'+ret_col].iloc[i]*test_pool.funded_amnt.iloc[i]\n",
    "\n",
    "## then define vector of all ones\n",
    "u = np.zeros(num_var) # cost vector\n",
    "for i in range(num_var):\n",
    "    u[i] = 1\n",
    "\n",
    "#Flora's licence    \n",
    "env = gp.Env(empty=True)\n",
    "env.setParam('WLSACCESSID', '9f11ef5f-f6b2-424f-b878-41f86258c5da')\n",
    "env.setParam('WLSSECRET', 'd898d09a-1223-4a71-931b-8800234f87c1')\n",
    "env.setParam('LICENSEID', 2415696)\n",
    "env.start()\n",
    "\n",
    "with gp.Model(env=env) as model:\n",
    "# Placing the variables in a pandas Series object will allow us to use the dot() function\n",
    "    x = pd.Series(model.addVars(num_var,vtype=GRB.BINARY))\n",
    "\n",
    "    model.setObjective(c.dot(x), GRB.MAXIMIZE)\n",
    "\n",
    "    model.addConstr(u.dot(x) <= num_loans)\n",
    "\n",
    "    # Formulate problem\n",
    "    model.optimize()\n",
    "    \n",
    "    # Extracting the optimal solution and optimal value\n",
    "    print('Optimal expected return:',model.ObjVal)\n",
    "    for i in range(num_var):\n",
    "        if x[i].X > 0: # most variables are zero, so we just print the non-zero variables\n",
    "            print('Choose loan',i+1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5235715",
   "metadata": {},
   "source": [
    "#### Partial Investments\n",
    "Now we want to decide which loan to invest in, and how much should the investment be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b5c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_col = 'ret_INTc'\n",
    "test_pool = two_stage[ret_col]['test data']\n",
    "num_var = test_pool.shape[0]\n",
    "num_loans = 10\n",
    "min_investment = 100\n",
    "\n",
    "# Define cost vector\n",
    "c = np.zeros(num_var)\n",
    "for i in range(num_var):\n",
    "    c[i] = test_pool['predicted_return_'+ret_col].iloc[i]*test_pool.funded_amnt.iloc[i]\n",
    "\n",
    "# Define vector of all ones\n",
    "u = np.zeros(num_var)\n",
    "for i in range(num_var):\n",
    "    u[i] = 1\n",
    "    \n",
    "env = gp.Env(empty=True)\n",
    "env.setParam('WLSACCESSID', '9f11ef5f-f6b2-424f-b878-41f86258c5da')\n",
    "env.setParam('WLSSECRET', 'd898d09a-1223-4a71-931b-8800234f87c1')\n",
    "env.setParam('LICENSEID', 2415696)\n",
    "env.start()\n",
    "\n",
    "with gp.Model(env=env) as model:\n",
    "\n",
    "    # Define the binary variables x and continuous variables y\n",
    "    x = pd.Series(model.addVars(num_var, vtype=GRB.BINARY))\n",
    "    y = pd.Series(model.addVars(num_var, lb=0, ub=test_pool.funded_amnt.values))\n",
    "\n",
    "    # Set the objective function\n",
    "    model.setObjective(c.dot(y), GRB.MAXIMIZE)\n",
    "\n",
    "    # Add constraints\n",
    "    for i in range(num_var):\n",
    "        model.addConstr(y[i] <= x[i] * test_pool.funded_amnt.iloc[i])\n",
    "        model.addConstr(y[i] >= min_investment * x[i])\n",
    "\n",
    "    # Update the budget constraint to be based on the sum of y\n",
    "    model.addConstr(u.dot(y) <= num_loans * test_pool.funded_amnt.mean()) # Adjust the budget constraint as needed\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    # Extracting the optimal solution and optimal value\n",
    "    print('Optimal expected return:', model.ObjVal)\n",
    "    for i in range(num_var):\n",
    "        if x[i].X > 0:\n",
    "            print('Choose loan', i+1, 'with investment amount:', y[i].X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5df76d",
   "metadata": {},
   "source": [
    "#### 5.3.2: Maximize profit with budget constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d267e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_col = 'ret_INTc'\n",
    "test_pool = two_stage[ret_col]['test data']\n",
    "num_var = test_pool.shape[0]\n",
    "num_loans = 100\n",
    "Budget = 1000000\n",
    "\n",
    "## first define cost vector\n",
    "c = np.zeros(num_var) # cost vector\n",
    "for i in range(num_var):\n",
    "    c[i] = test_pool['predicted_return_'+ret_col].iloc[i]*test_pool.funded_amnt.iloc[i]\n",
    "\n",
    "## then define vector of all ones\n",
    "u = np.zeros(num_var) # cost vector\n",
    "for i in range(num_var):\n",
    "    u[i] = 1\n",
    "    \n",
    "env = gp.Env(empty=True)\n",
    "env.setParam('WLSACCESSID', '9f11ef5f-f6b2-424f-b878-41f86258c5da')\n",
    "env.setParam('WLSSECRET', 'd898d09a-1223-4a71-931b-8800234f87c1')\n",
    "env.setParam('LICENSEID', 2415696)\n",
    "env.start()\n",
    "\n",
    "with gp.Model(env=env) as model:\n",
    "\n",
    "    # Placing the variables in a pandas Series object will allow us to use the dot() function\n",
    "    x = pd.Series(model.addVars(num_var,vtype=GRB.BINARY))\n",
    "    amt = pd.Series(test_pool[0:num_var].loan_amnt)\n",
    "\n",
    "    model.setObjective(c.dot(x), GRB.MAXIMIZE)\n",
    "\n",
    "    model.addConstr(u.dot(x) <= num_loans)\n",
    "    model.addConstr(u.dot(x) >= 0.9*num_loans)\n",
    "    model.addConstr(amt.dot(x) <= Budget)\n",
    "\n",
    "    model.optimize()    \n",
    "    \n",
    "    # Extracting the optimal solution and optimal value\n",
    "    print('Optimal expected return:',model.ObjVal)\n",
    "    for i in range(num_var):\n",
    "        if x[i].X > 0: # most variables are zero, so we just print the non-zero variables\n",
    "            print('Choose loan',i+1) \n",
    "    \n",
    "    opt_sln_IP2 = np.zeros(num_var)\n",
    "    for i in range(num_var):\n",
    "        opt_sln_IP2[i] = x[i].X\n",
    "    \n",
    "    print(sum(opt_sln_IP2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9defb56",
   "metadata": {},
   "source": [
    "#### Sanity check\n",
    "Intuitively the optimal solution $x^*$ should sequentially choose the highest return loans. We compare $x^*$ with opt_sln below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7934ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.sort(c)\n",
    "temp = temp[::-1] # in descending order\n",
    "cutoff = temp[100]\n",
    "y = np.zeros(num_var)\n",
    "for i in range(num_var):\n",
    "    if cutoff<c[i]:\n",
    "        y[i]=1\n",
    "print(\"number of entries that differ:\", int((y - opt_sln_IP2).sum()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b5918",
   "metadata": {},
   "source": [
    "#### 5.3.3: Maximize profit with risk-return tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we need to train a clustering model to estimate the variance of return\n",
    "n_clusters = 75\n",
    "train_set = data_dict['train_set']\n",
    "data_train = final_data.loc[train_set,:]\n",
    "\n",
    "# Create a dataframe for testing, including the score\n",
    "data_test = two_stage[ret_col]['test data']\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data_dict['X_train'])\n",
    "data_train['clusID'] = kmeans.predict(data_dict['X_train'])\n",
    "data_test['clusID'] = kmeans.predict(data_dict['X_test'])\n",
    "data_test['volatility'] = 0\n",
    "\n",
    "for idx in range(n_clusters):\n",
    "    std_clus = np.std(data_train[ret_col][data_train.clusID == idx])\n",
    "    data_test.volatility[data_test.clusID == idx] = std_clus\n",
    "\n",
    "## Specify the parameters of the optimization model, beta: penalty factor on the risk\n",
    "beta = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b40a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_col = 'ret_INTc'\n",
    "test_pool = two_stage[ret_col]['test data']\n",
    "num_var = test_pool.shape[0]\n",
    "num_loans = 100\n",
    "Budget = 1000000\n",
    "\n",
    "## define objective\n",
    "c = np.zeros(num_var) # cost vector\n",
    "for i in range(num_var):\n",
    "    c[i] = (test_pool['predicted_return_'+  ret_col].iloc[i] -\n",
    "            beta * test_pool.volatility.iloc[i]) * test_pool.loan_amnt.iloc[i]\n",
    "    \n",
    "## then define vector of all ones\n",
    "u = np.zeros(num_var) # cost vector\n",
    "for i in range(num_var):\n",
    "    u[i] = 1\n",
    "    \n",
    "env = gp.Env(empty=True)\n",
    "env.setParam('WLSACCESSID', '9f11ef5f-f6b2-424f-b878-41f86258c5da')\n",
    "env.setParam('WLSSECRET', 'd898d09a-1223-4a71-931b-8800234f87c1')\n",
    "env.setParam('LICENSEID', 2415696)\n",
    "env.start()\n",
    "\n",
    "with gp.Model(env=env) as model:\n",
    "\n",
    "    # Placing the variables in a pandas Series object will allow us to use the dot() function\n",
    "    x = pd.Series(model.addVars(num_var,vtype=GRB.BINARY))\n",
    "    amt = pd.Series(test_pool[0:num_var].loan_amnt)\n",
    "\n",
    "    model.setObjective(c.dot(x), GRB.MAXIMIZE)\n",
    "\n",
    "    model.addConstr(u.dot(x) <= num_loans)\n",
    "    model.addConstr(u.dot(x) >= 0.9*num_loans)\n",
    "    model.addConstr(amt.dot(x) <= Budget)\n",
    "\n",
    "    model.optimize()    \n",
    "    \n",
    "    # Extracting the optimal solution and optimal value\n",
    "    print('Optimal expected return:',model.ObjVal)\n",
    "    for i in range(num_var):\n",
    "        if x[i].X > 0: # most variables are zero, so we just print the non-zero variables\n",
    "            print('Choose loan',i+1)  \n",
    "    \n",
    "    opt_sln_IP3 = np.zeros(num_var)\n",
    "    for i in range(num_var):\n",
    "        opt_sln_IP3[i] = x[i].X\n",
    "    \n",
    "    print(sum(opt_sln_IP3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62800d4e",
   "metadata": {},
   "source": [
    "#### Loop to run for multiple Cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the possible values for the parameters\n",
    "cluster_nums = [20, 75, 50, 100, 200]\n",
    "loan_nums = [100, 200]\n",
    "betas = [0, 0.2, 0.4, 0.6, 0.75, 0.8, 0.9]\n",
    "\n",
    "# Initialize an empty dataframe to store the results\n",
    "results_df = pd.DataFrame(columns=['Loan_Num', 'Cluster_Num', 'Beta', 'Return', 'Return %', 'Num_Loans_Kept', 'Loans_Kept'])\n",
    "\n",
    "train_set = data_dict['train_set']\n",
    "data_train = data.loc[train_set,:]\n",
    "data_test = two_stage[ret_col]['test data']\n",
    "Budget = 1000000\n",
    "\n",
    "for cluster_num in cluster_nums:\n",
    "    for loan_num in loan_nums:\n",
    "        for beta in betas:\n",
    "            \n",
    "            # Set the parameters\n",
    "            n_clusters = cluster_num\n",
    "            num_loans = loan_num\n",
    "            \n",
    "            # Clustering\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data_dict['X_train'])\n",
    "            data_train['clusID'] = kmeans.predict(data_dict['X_train'])\n",
    "            data_test['clusID'] = kmeans.predict(data_dict['X_test'])\n",
    "            data_test['volatility'] = 0\n",
    "            \n",
    "            for idx in range(n_clusters):\n",
    "                std_clus = np.std(data_train[ret_col][data_train.clusID == idx])\n",
    "                data_test.volatility[data_test.clusID == idx] = std_clus\n",
    "            \n",
    "            # Optimization\n",
    "            ret_col = 'ret_INTc'\n",
    "            test_pool = two_stage[ret_col]['test data']\n",
    "            num_var = test_pool.shape[0]\n",
    "            \n",
    "            c = np.zeros(num_var)\n",
    "            for i in range(num_var):\n",
    "                c[i] = (test_pool['predicted_return_'+ ret_col].iloc[i] -\n",
    "                        beta * test_pool.volatility.iloc[i]) * test_pool.loan_amnt.iloc[i]\n",
    "                \n",
    "            u = np.zeros(num_var)\n",
    "            for i in range(num_var):\n",
    "                u[i] = 1\n",
    "\n",
    "            env = gp.Env(empty=True)\n",
    "            env.setParam('WLSACCESSID', '9f11ef5f-f6b2-424f-b878-41f86258c5da')\n",
    "            env.setParam('WLSSECRET', 'd898d09a-1223-4a71-931b-8800234f87c1')\n",
    "            env.setParam('LICENSEID', 2415696)\n",
    "            env.start()\n",
    "\n",
    "            with gp.Model(env=env) as model:\n",
    "                x = pd.Series(model.addVars(num_var,vtype=GRB.BINARY))\n",
    "                amt = pd.Series(test_pool[0:num_var].loan_amnt)\n",
    "                model.setObjective(c.dot(x), GRB.MAXIMIZE)\n",
    "                model.addConstr(u.dot(x) <= num_loans)\n",
    "                model.addConstr(u.dot(x) >= 0.9*num_loans)\n",
    "                model.addConstr(amt.dot(x) <= Budget)\n",
    "                model.optimize()    \n",
    "\n",
    "                # Extract the optimal value\n",
    "                optimal_return = model.ObjVal\n",
    "                return_percentage = (optimal_return / Budget) * 100\n",
    "\n",
    "                # Extract the number of loans kept\n",
    "                num_loans_kept = sum(x[i].X for i in range(num_var))\n",
    "                \n",
    "                # Extract the list of loans kept\n",
    "                loans_kept = [i+1 for i in range(num_var) if x[i].X > 0]\n",
    "\n",
    "                # Append the results to the dataframe\n",
    "                results_df = results_df.append({\n",
    "                    'Loan_Num': loan_num,\n",
    "                    'Cluster_Num': cluster_num,\n",
    "                    'Beta': beta,\n",
    "                    'Return': optimal_return,\n",
    "                    'Return %': return_percentage,\n",
    "                    'Num_Loans_Kept': num_loans_kept,\n",
    "                    'Loans_Kept': loans_kept\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Show the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fc734",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_results_df = results_df.sort_values(by='Return %', ascending=False)\n",
    "sorted_results_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4501cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for loan_nums = 100\n",
    "filtered_df = sorted_results_df[sorted_results_df['Loan_Num'] == 100]\n",
    "\n",
    "# Cluster numbers of interest\n",
    "cluster_nums = [20, 50, 75, 100, 200]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for beta in [0, 0.2, 0.4, 0.6, 0.75, 0.8, 0.9]:\n",
    "    subset = filtered_df[filtered_df['Beta'] == beta]\n",
    "    subset = subset[subset['Cluster_Num'].isin(cluster_nums)]\n",
    "    plt.plot(subset['Cluster_Num'], subset['Return %'], '-o', label=f'Beta={beta}')\n",
    "\n",
    "plt.title('Return % vs. Number of Clusters for Loan_Num = 100')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Return %')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee817352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the betas and clusters\n",
    "betas = [0, 0.2, 0.4, 0.6, 0.75, 0.8, 0.9]\n",
    "cluster_nums = [20, 50, 75, 100, 200]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for cluster in cluster_nums:\n",
    "    subset = filtered_df[filtered_df['Cluster_Num'] == cluster]\n",
    "    plt.plot(subset['Beta'], subset['Return %'], '-o', label=f'Cluster={cluster}')\n",
    "\n",
    "plt.title('Return % vs. Beta for Loan_Num = 100')\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Return %')\n",
    "plt.xticks(betas)  # Ensure all betas are shown on the x-axis\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for beta = 0.75\n",
    "filtered_df = sorted_results_df[sorted_results_df['Beta'] == 0.75]\n",
    "\n",
    "# Define the loan numbers and clusters\n",
    "loan_nums = [50, 100, 200]\n",
    "cluster_nums = [20, 50, 75, 100, 200]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for loan_num in loan_nums:\n",
    "    subset = filtered_df[filtered_df['Loan_Num'] == loan_num]\n",
    "    plt.plot(subset['Cluster_Num'], subset['Return %'], '-o', label=f'Loan_Num={loan_num}')\n",
    "\n",
    "plt.title('Return % vs. Cluster Number for Beta = 0.75')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Return %')\n",
    "plt.xticks(cluster_nums)  # Ensure all cluster numbers are shown on the x-axis\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1dcbd",
   "metadata": {},
   "source": [
    "#### 5.3.4 Visualization: violin plots for the expected returns of the above strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9563b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool['label'] = ['test_pool']*test_pool.shape[0]\n",
    "\n",
    "# now we create a df for OPT of IP2\n",
    "test_pool['chosen_IP2'] = opt_sln_IP2\n",
    "df2 = test_pool[test_pool.chosen_IP2 == 1].copy() # df containing only rows chosen by IP2\n",
    "test_pool = test_pool.drop(columns=['chosen_IP2']) # drop this columns in order to append\n",
    "df2 = df2.drop(columns=['chosen_IP2']) # drop this columns in order to append\n",
    "df2['label'] = ['IP2']*df2.shape[0]\n",
    "\n",
    "# create a df for OPT of IP3\n",
    "test_pool['chosen_IP3'] = opt_sln_IP3\n",
    "df3 = test_pool[test_pool.chosen_IP3 == 1].copy() # df containing only rows chosen by IP3\n",
    "test_pool = test_pool.drop(columns=['chosen_IP3']) # drop this columns in order to append\n",
    "df3 = df3.drop(columns=['chosen_IP3']) # drop this columns in order to append\n",
    "df3['label'] = ['IP3']*df3.shape[0]\n",
    "\n",
    "# concatenate the dataframes\n",
    "df_big = test_pool.append([df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(y=df_big[\"predicted_return_ret_INTc\"], x=df_big[\"label\"], \n",
    "                    data=df_big, order=['test_pool','IP2','IP3'])\n",
    "ax.set_title(\"Ditribution of expected return of the selected loans\")\n",
    "ax.set_xlabel(\"Subset of loans\")\n",
    "ax.set_ylabel(\"ret_INTc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ab5b0",
   "metadata": {},
   "source": [
    "### 5.4. Sensitivity analysis of the optimization solution by varying the budgets and the number of loans invested in\n",
    "\n",
    "Build a trade-off curve between the beta value and the optimization objective (expected return). For this we loop through various values of beta from 0.1 through some large number in steps of 0.1 say. Then we create a plot of different pairs of means and stdevns of the expected return of the portfolios as you vary beta. The two axes will then be mean (return) and stdevn (risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_col = 'ret_INTc'\n",
    "num_var = test_pool.shape[0]\n",
    "Budget = 100000\n",
    "beta_min = 0.1\n",
    "step = 0.15\n",
    "num_beta = 10\n",
    "u = np.zeros(num_var) # units vector\n",
    "\n",
    "for i in range(num_var):\n",
    "    u[i] = 1\n",
    "\n",
    "amt = pd.Series(test_pool[0:num_var].loan_amnt)\n",
    "\n",
    "table = np.zeros([num_beta,2]) # store the return and risk\n",
    "\n",
    "env = gp.Env(empty=True)\n",
    "env.setParam('WLSACCESSID', '9f11ef5f-f6b2-424f-b878-41f86258c5da')\n",
    "env.setParam('WLSSECRET', 'd898d09a-1223-4a71-931b-8800234f87c1')\n",
    "env.setParam('LICENSEID', 2415696)\n",
    "env.start()\n",
    "\n",
    "for j in range(num_beta):\n",
    "    beta = beta_min + j*step\n",
    "    \n",
    "    c = np.zeros(num_var) # cost vector\n",
    "    for i in range(num_var):\n",
    "        c[i] = (test_pool['predicted_return_'+  ret_col].iloc[i] - beta * test_pool.volatility.iloc[i]) * test_pool.loan_amnt.iloc[i]\n",
    "    \n",
    "    with gp.Model(env=env) as model:\n",
    "\n",
    "        x = pd.Series(model.addVars(num_var,vtype=GRB.BINARY))\n",
    "\n",
    "        model.setObjective(c.dot(x), GRB.MAXIMIZE)\n",
    "    \n",
    "        model.addConstr(u.dot(x) <= num_loans)\n",
    "        model.addConstr(u.dot(x) >= 0.9*num_loans)\n",
    "        model.addConstr(amt.dot(x) <= Budget)\n",
    "\n",
    "        model.optimize() \n",
    "    \n",
    "        opt = np.zeros(num_var)\n",
    "        for k in range(num_var):\n",
    "            opt[k] = x[k].X\n",
    "        test_pool['chosen'] = opt\n",
    "        df = test_pool[test_pool.chosen == 1]\n",
    "        table[j,0] = df['predicted_return_'+  ret_col].sum()\n",
    "        table[j,1] = df.volatility.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(table[:,0],table[:,1])\n",
    "plt.xlabel(\"return\")\n",
    "plt.ylabel(\"risk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35300b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_portfolio(Budget, ret_col, data, data_dict, two_stage, n_clusters=20, beta_min=0.1, step=0.1, num_loans=100, num_beta=10):\n",
    "    train_set = data_dict['train_set']\n",
    "    data_train = data.loc[train_set, :]\n",
    "    data_test = two_stage[ret_col]['test data']\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(data_dict['X_train'])\n",
    "    data_train['clusID'] = kmeans.predict(data_dict['X_train'])\n",
    "    data_test['clusID'] = kmeans.predict(data_dict['X_test'])\n",
    "    data_test['volatility'] = 0\n",
    "\n",
    "    for idx in range(n_clusters):\n",
    "        std_clus = np.std(data_train[ret_col][data_train.clusID == idx])\n",
    "        data_test.volatility[data_test.clusID == idx] = std_clus\n",
    "\n",
    "    num_var = data_test.shape[0]\n",
    "    u = np.ones(num_var) \n",
    "    amt = pd.Series(data_test[0:num_var].loan_amnt)\n",
    "\n",
    "    table = np.zeros([num_beta,2])  # store the return and risk\n",
    "    env = gp.Env(empty=True)\n",
    "    env.setParam('WLSACCESSID', '9f11ef5f-f6b2-424f-b878-41f86258c5da')\n",
    "    env.setParam('WLSSECRET', 'd898d09a-1223-4a71-931b-8800234f87c1')\n",
    "    env.setParam('LICENSEID', 2415696)\n",
    "    env.start()\n",
    "\n",
    "    for j in range(num_beta):\n",
    "        beta = beta_min + j*step\n",
    "        c = np.array([(data_test['predicted_return_'+  ret_col].iloc[i] - beta * data_test.volatility.iloc[i]) * data_test.loan_amnt.iloc[i] for i in range(num_var)])\n",
    "        \n",
    "        with gp.Model(env=env) as model:\n",
    "            x = pd.Series(model.addVars(num_var, vtype=GRB.BINARY))\n",
    "            model.setObjective(c.dot(x), GRB.MAXIMIZE)\n",
    "            model.addConstr(u.dot(x) <= num_loans)\n",
    "            model.addConstr(u.dot(x) >= 0.9*num_loans)\n",
    "            model.addConstr(amt.dot(x) <= Budget)\n",
    "            model.optimize() \n",
    "\n",
    "            opt = [x[i].X for i in range(num_var)]\n",
    "            data_test['chosen'] = opt\n",
    "            df = data_test[data_test.chosen == 1]\n",
    "            table[j,0] = df['predicted_return_'+  ret_col].sum()\n",
    "            table[j,1] = df.volatility.sum()\n",
    "\n",
    "    return table\n",
    "\n",
    "# Running the function with different combinations of Budget and ret_col\n",
    "Budgets = [1000000, 200000000]\n",
    "ret_cols = ['ret_INTc', 'ret_PESS', 'ret_OPT']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for Budget in Budgets:\n",
    "    for ret_col in ret_cols:\n",
    "        table = optimize_portfolio(Budget, ret_col, data, data_dict, two_stage)\n",
    "        plt.plot(table[:,0], table[:,1], label=f'Budget: {Budget}, Return Column: {ret_col}')\n",
    "\n",
    "plt.title('Risk vs Return for various Budget and ret_col combinations')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Risk')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
